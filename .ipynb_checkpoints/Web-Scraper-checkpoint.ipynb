{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b99bd58b-dabe-4ec9-8914-fac013ec08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b4feaa48-544b-4ba4-8c29-16c80596c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize browser\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "wait = WebDriverWait(driver, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1afdd237-2720-4aa2-a4c2-516341bf5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBC News section URLs\n",
    "section_urls = [\n",
    "    'https://www.bbc.com/innovation',\n",
    "    'https://www.bbc.com/business',\n",
    "    'https://www.bbc.com/news/science_and_environment',\n",
    "    'https://www.bbc.com/culture/entertainment-news',\n",
    "    'https://www.bbc.com/arts',\n",
    "    'https://www.bbc.com/travel'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e146fa19-fbd3-4362-b065-1299a345a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradual_scroll():\n",
    "    \"\"\"Scroll gradually to trigger lazy-loading\"\"\"\n",
    "    current_position = 4500\n",
    "    scroll_increment = 500  # pixels\n",
    "    max_attempts = 10\n",
    "    \n",
    "    for _ in range(max_attempts):\n",
    "        driver.execute_script(f\"window.scrollTo(0, {current_position});\")\n",
    "        current_position += scroll_increment\n",
    "        time.sleep(1.0)  # Adjust based on connection speed\n",
    "        \n",
    "        # Check if \"More\" section becomes visible\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, \"//h2[contains(text(), 'More')]\")\n",
    "            print(\"Found 'More' section!\")\n",
    "            return True\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"Failed to find 'More on' section after scrolling\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c86b3b56-ecf7-42e6-8f5d-ca4c918e1bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_articles(url):\n",
    "    driver.get(url)\n",
    "    articles_data = []\n",
    "    \n",
    "    if not gradual_scroll():\n",
    "        return articles_data\n",
    "\n",
    "    # print(\"waiting to read links\")\n",
    "    # time.sleep(10)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get all article cards\n",
    "            cards = driver.find_elements(By.CSS_SELECTOR, 'div[class*=\"sc-c5803051-0 izsbSA\"]')\n",
    "            # cardstack = driver.find_elements(By.CSS_SELECTOR, 'a[data-testid=\"internal-link\"][class*=\"sc-c5803051-0 izsbSA\"]')\n",
    "            \n",
    "            # Extract data from each card\n",
    "            for card in cards:\n",
    "                try:\n",
    "                    url = card.get_attribute('href')\n",
    "                    # headline = card.find_element(By.CSS_SELECTOR, 'h2[data-testid=\"card-headline\"]').text\n",
    "                    # category = card.find_element(By.CSS_SELECTOR, 'span[data-testid=\"card-metadata-tag\"]').text\n",
    "                    \n",
    "                    articles_data.append({\n",
    "                        # 'headline': headline,\n",
    "                        # 'category': category,\n",
    "                        'url': url\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing card: {str(e)}\")\n",
    "                    continue\n",
    "            print(f\"Collected {len(articles_data)} articles so far\")\n",
    "        \n",
    "            # Scroll to bottom to expose pagination controls\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(1)\n",
    "            # scroll up a bit\n",
    "            driver.execute_script(\"window.scrollBy(0, -300)\")\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # Find and click next button\n",
    "            next_button = wait.until(EC.element_to_be_clickable(\n",
    "                (By.CSS_SELECTOR, 'button[data-testid=\"pagination-next-button\"]:not([disabled])')))\n",
    "            next_button.click()\n",
    "            print(\"Clicked Next Page button\")\n",
    "            \n",
    "            # Reset scroll position for new page\n",
    "            driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "            time.sleep(1.5)\n",
    "            gradual_scroll()  # Find \"More\" section again\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Pagination ended: {str(e)}\")\n",
    "            break\n",
    "            \n",
    "    return articles_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b2acbc67-f40a-4e72-bde6-a0409c013d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 'More' section!\n",
      "Collected 1 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 2 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 3 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 4 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 5 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 6 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 7 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 8 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 9 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 10 articles so far\n",
      "Clicked Next Page button\n",
      "Found 'More' section!\n",
      "Collected 11 articles so far\n",
      "Pagination ended: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0129FC03+61635]\n",
      "\tGetHandleVerifier [0x0129FC44+61700]\n",
      "\t(No symbol) [0x010C05D3]\n",
      "\t(No symbol) [0x0110899E]\n",
      "\t(No symbol) [0x01108D3B]\n",
      "\t(No symbol) [0x01150E12]\n",
      "\t(No symbol) [0x0112D2E4]\n",
      "\t(No symbol) [0x0114E61B]\n",
      "\t(No symbol) [0x0112D096]\n",
      "\t(No symbol) [0x010FC840]\n",
      "\t(No symbol) [0x010FD6A4]\n",
      "\tGetHandleVerifier [0x01524523+2701795]\n",
      "\tGetHandleVerifier [0x0151FCA6+2683238]\n",
      "\tGetHandleVerifier [0x0153A9EE+2793134]\n",
      "\tGetHandleVerifier [0x012B68C5+155013]\n",
      "\tGetHandleVerifier [0x012BCFAD+181357]\n",
      "\tGetHandleVerifier [0x012A7458+92440]\n",
      "\tGetHandleVerifier [0x012A7600+92864]\n",
      "\tGetHandleVerifier [0x01291FF0+5296]\n",
      "\tBaseThreadInitThunk [0x76747BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x77B1C0CB+107]\n",
      "\tRtlClearBits [0x77B1C04F+191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "url = \"https://www.bbc.com/innovation\"\n",
    "articles_data = scrape_articles(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e11caf88-d7e8-4812-a42f-68a673b2fc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(articles_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f22e929e-ad13-4dd7-83c4-1e0f0813e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': None}, {'url': None}, {'url': None}, {'url': None}, {'url': None}, {'url': None}, {'url': None}, {'url': None}, {'url': None}, {'url': None}, {'url': None}]\n"
     ]
    }
   ],
   "source": [
    "print(articles_data)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9554e046-c6f9-486d-ade5-d9b8126ef5e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = pd.DataFrame(\u001b[43mall_articles\u001b[49m)\n\u001b[32m      3\u001b[39m df = df.drop_duplicates(subset=[\u001b[33m'\u001b[39m\u001b[33murl\u001b[39m\u001b[33m'\u001b[39m])  \u001b[38;5;66;03m# Remove duplicates\u001b[39;00m\n\u001b[32m      4\u001b[39m df.to_csv(\u001b[33m'\u001b[39m\u001b[33mbbc_scraped_news_articles.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'all_articles' is not defined"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "df = pd.DataFrame(articles_data)\n",
    "df = df.drop_duplicates(subset=['url'])  # Remove duplicates\n",
    "df.to_csv('bbc_scraped_news_articles.csv', index=False)\n",
    "print(f\"Saved {len(df)} articles to CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f2bf2-f193-44fe-8736-69e20fe8ac86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (news-classifier)",
   "language": "python",
   "name": "news-classifier-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
